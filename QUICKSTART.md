# Schnellstart-Anleitung

FÃ¼r schnelles Testen des Systems auf deinem Entwicklungsrechner (vor Raspberry Pi Deployment).

## 1. Dependencies installieren

```bash
# Virtual Environment erstellen
python -m venv venv

# Aktivieren (Windows)
venv\Scripts\activate

# Aktivieren (Linux/Mac)
source venv/bin/activate

# Packages installieren
pip install -r requirements.txt
```

## 2. System testen

```bash
# Quick Start Script (prÃ¼ft alle Komponenten)
python quickstart.py
```

Dieses Script testet:
- âœ“ Alle Python-Dependencies
- âœ“ config.yaml Konfiguration
- âœ“ Datenbank-Initialisierung
- âœ“ AI-Categorizer (optional)

## 3. Server starten

```bash
# Hauptsystem starten (Linux/Mac)
python main.py

# Oder mit Development Script (Windows)
.\start_dev.bat --web

```

Dashboard Ã¶ffnen: http://localhost:5000

## 4. Testen

### Unit Tests ausfÃ¼hren

```bash
# Einzelner Test
python -m pytest tests/test_document_processor.py -v

# Alle Tests
python -m pytest tests/ -v
```

### Funktionen testen

**Dokument hochladen:**
1. Dashboard Ã¶ffnen
2. Upload-Bereich nutzen (Drag & Drop oder Klicken)
3. PDF/Bild hochladen
4. System verarbeitet automatisch

**Suche testen:**
1. Suchfeld oben rechts
2. Suchbegriff eingeben
3. Ergebnisse erscheinen

**Chatbot testen:**
1. Ollama muss laufen: `ollama serve`
2. Model laden: `ollama pull tinyllama`
3. Chatbot-Button unten rechts klicken
4. Fragen stellen

## 5. Troubleshooting

### Fehler: "No module named 'app'"

```bash
# Im Projekt-Root-Verzeichnis sein:
cd OrganisationsAI
python main.py
```

### Fehler: "Tesseract not found"

**Windows:**
1. https://github.com/UB-Mannheim/tesseract/wiki downloaden
2. Installieren nach C:\Program Files\Tesseract-OCR
3. PATH aktualisieren

**Linux:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-deu
```

### Fehler: "Ollama connection failed"

Chatbot funktioniert auch ohne Ollama (Fallback-Responses).

FÃ¼r volle FunktionalitÃ¤t:
```bash
# Ollama installieren
curl -fsSL https://ollama.com/install.sh | sh

# Model laden
ollama pull tinyllama

# Server starten
ollama serve
```

### Port 5000 bereits belegt

In `config.yaml` Ã¤ndern:
```yaml
web:
  port: 8000  # Anderen Port wÃ¤hlen
```

## 6. Entwicklung

### Code-Struktur

```
app/
â”œâ”€â”€ scanner_handler.py      # Scanner-Integration
â”œâ”€â”€ document_processor.py   # OCR & Analyse
â”œâ”€â”€ categorizer.py           # KI-Kategorisierung
â”œâ”€â”€ storage_manager.py       # Datei-Verwaltung
â”œâ”€â”€ data_extractor.py        # CSV-Extraktion
â”œâ”€â”€ database.py              # SQLite DB
â”œâ”€â”€ search_engine.py         # BM25-Suche
â”œâ”€â”€ server.py                # Flask Server
â”œâ”€â”€ upload_handler.py        # File Upload
â”œâ”€â”€ ollama_client.py         # Chatbot
â””â”€â”€ static/                  # Frontend
    â”œâ”€â”€ index.html
    â”œâ”€â”€ css/style.css
    â””â”€â”€ js/app.js, chatbot.js
```

### Neue Kategorie hinzufÃ¼gen

In `config.yaml`:
```yaml
categories:
  main:
    - MeineNeueKategorie
  
  keywords:
    MeineNeueKategorie:
      - keyword1
      - keyword2
```

In `categorizer.py` neue Subkategorie-Logik hinzufÃ¼gen (optional).

### API nutzen

Alle Endpoints unter `/api/*`:

```bash
# Statistiken
curl http://localhost:5000/api/stats/overview

# Suche
curl "http://localhost:5000/api/documents/search?q=rechnung"

# Versicherungen
curl http://localhost:5000/api/insurance/list
```

## 7. Produktiv-Deployment

Siehe [README.md](README.md) fÃ¼r vollstÃ¤ndige Raspberry Pi Installation.

Kurzversion:
```bash
# Auf Raspberry Pi
git clone <repo> /home/pi/OrganisationsAI
cd /home/pi/OrganisationsAI
sudo ./install.sh

# System startet automatisch beim Booten
```

---

**Viel Erfolg! ðŸš€**

Bei Problemen: Issue auf GitHub erstellen oder Logs prÃ¼fen (`document_manager.log`)
